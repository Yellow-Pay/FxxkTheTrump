#1: Individual NF acceleration: Offloading 
	# Discussion - GPU software packet processing acceleration
	To accelerate software packet processing, previous work has proposed using GPU ["PacketShader"], specialized network processor (NP) [2, 5], and hardware switches ["Duet"]. 
	GPU is primarily designed for graphic processing and recently extended to other applications with massive data parallelism.
	"GPU is more suitable for batch operations".
	Han, et al. ["PacketShader"], show that using GPU can achieve 40Gbps packet switching speed. 
	However, "batch operations incur high delay". ["ClickNP"]

	["SIGCOMM 2010"] "PacketShader": a GPU-Accelerated Software Router 
	We present PacketShader, a high-performance software router framework for general packet processing with Graphics Processing Unit (GPU)  acceleration. PacketShader "exploits the  massively-parallel processing power of GPU" to address the CPU bottleneck in current software routers.
	Combined with our high-performance packet I/O engine, PacketShader "outperforms existing software routers by more than a factor of four, forwarding 64B IPv4 packets at 39 Gbps on a single commodity PC". 
	We have implemented IPv4 and IPv6 forwarding, OpenFlow switching, and IPsec tunneling to demonstrate the flexibility and performance advantage of PacketShader. 
	The evaluation results show that GPU brings significantly higher throughput over the CPU-only implementation, confirming the effectiveness of GPU for computation and memory-intensive operations in packet processing.
	
	["SIGCOMM 2014"] "Duet": Cloud Scale Load Balancing with Hardware and Software
	"Load balancing" is a foundational function of datacenter infrastructures and is critical to the performance of online services hosted in datacenters. As the demand for cloud services grows,  expensive and hard-to-scale dedicated hardware load balancers are being replaced with software load balancers that scale using a distributed data plane that runs on commodity servers. 
	"Software load balancers offer low cost, high availability and high flexibility", but "suffer high latency and low capacity per load balancer", making them less than ideal for applications that demand either high throughput, or low latency or both. 
	In this paper, we present "DUET", which "offers all the benefits of software load balancer, along with low latency and high availability – at next to no cost".
	We do this "by exploiting a hitherto overlooked resource in the data center networks – the switches themselves". 
	We show how to embed the load balancing functionality into existing hardware switches, thereby achieving organic scalability at no extra cost. 
	For flexibility and high availability, "DUET seamlessly integrates the switch-based load balancer with a small deployment of software load balancer". 
	We  enumerate and solve several architectural and algorithmic challenges involved in building such a hybrid load balancer. 
	We evaluate DUET using a prototype implementation, as well as extensive simulations driven by traces from our production data centers. 
	Our evaluation shows that DUET provides "10x more capacity than a software load balancer, at a fraction of a cost, while reducing latency by a factor of 10 or more, and is able to quickly adapt to network dynamics including failures".

	# Discussion - computation batching and GPU offloading
	Historically, the Click modular router has laid the foundation for a programmable router framework, and follow-up work has improved Click’s performance.
	"DoubleClick" has demonstrated the potential of computation batching.
	"Snap" adds GPU-offloading abstractions to Click. ["NBA"]

	["ApSys 2012"] "DoubleClick": The Power of Batching in the Click Modular Router 
	The Click modular router has been one of the most popular software router platforms for rapid prototyping and new protocol development. Unfortunately, its internal architecture has not caught up with recent hardware advancements, and the performance remains sub-optimal in high-speed networks despite its benefit of flexible module composition.
	In this work, we identify the performance bottlenecks of the existing Click router and extend it to scale with modern computer systems. Our improvements "focus on both I/O and computation batching", and "include various optimizations for multi-core systems and multi-queue network cards".
	We find that these techniques improve the performance by almost a factor of 10, and the maximum throughput reaches 28 Gbps of minimum-sized IPv4 packet forwarding speed on a single machine.

	["ANCS 2013"] "Snap":Fast and flexible: Parallel packet processing with GPUs and click
	We introduce Snap, a framework for packet processing that "outperforms traditional software routers" by "exploiting the parallelism available on modern GPUs". 
	While obtaining high performance, it remains extremely flexible, with packet processing tasks implemented as simple modular elements that are composed to build fully functional routers and switches. 
	Snap is based on the Click modular router, which it extends by adding new architectural features that support batched packet processing, memory structures optimized for offloading to coprocessors, and asynchronous scheduling with in-order completion. 
	We show that Snap "can run complex pipelines at high speeds on commodity PC hardware" by building an IP router incorporating both an IDS-like full-packet string matcher and an SDN-like packet classifier. 
	In this configuration, Snap "is able to forward 40 million packets per second, saturating four 10 Gbps NICs at packet sizes as small as 128 byes". This represents "an increase in throughput of nearly 4x" over the baseline Click running comparable elements on the CPU.	

	# Discussion - Developing network applications on specialized networking hardware & providing high level programming tools
	Here has also been a long line of work on "developing network applications on specialized networking hardware" including "NPUs" ["HotSDN 2013"], "FPGAs" ["NetFPGA"] and "programmable switches" ["SIGCOMM 2013"]. 
	Recent work including "P4" and "Packet Transactions" have looked at "providing high level programming tools for such hardware".
	Our work focuses on network programming for general purpose CPUs and is complementary to this work. ["NetBricks"]

	["HotSDN 2013"] Protocol-Oblivious Forwarding: Unleash the Power of SDN through a Future-Proof Forwarding Plane
	["In Workshop on Programmable routers for extensible services of tomorrow, 2008"] "NetFPGA": Reusable Router Architecture for Experimental Research
	["SIGCOMM 2013"] Forwarding Metamorphosis: Fast Programmable Match-Action Processing in Hardware for SDN
	["SIGCOMM 2014"] "P4": Programming Protocol-Independent Packet Processors
	["SIGCOMM 2016"] "Packet Transactions": High-Level Programming for Line-Rate Switches

	# Discussion - offloading functionality to GPUs/FPGAs
	Recent extensions to Click, e.g., "NBA" and "ClickNP", have looked at how to implement optimized Click elements through the use of GPUs (NBA) and FPGAs (ClickNP).
	While offloading functionality to such devices can yield great performance improvements, this is orthogonal to our work. ["NetBricks"]

	["EuroSys 2015"] "NBA" (Network  Balancing  Act) - A  High-performance  Packet  Processing  Framework for  Heterogeneous  Processors
	We present the NBA "framework", which extends the architecture  of  the  Click  modular  router  to  exploit  modern  hardware,  adapts  to  different  hardware  configurations, and  reaches  close  to  their  maximum  performance  without  manual  optimization.
	NBA  "takes  advantages  of  existing  performance-excavating  solutions  such  as  batch  processing, NUMA-aware memory management, and receive-side scaling with multi-queue network cards". 
	Its abstraction "resembles  Click  but  also  hides  the  details  of  architecture-specific optimization, batch processing that handles the path diversity  of  individual  packets,  CPU/GPU  load  balancing, and complex hardware resource mappings due to multi-core CPUs and multi-queue network cards". 
	We have implemented four  sample  applications: an  IPv4  and  an  IPv6  router, an IPsec encryption gateway, and an intrusion detection system (IDS)  with  Aho-Corasik  and  regular  expression  matching. 
	The IPv4/IPv6 router "performance reaches the line rate on a  commodity  80  Gbps  machine, and  the  performances  of the IPsec gateway and the IDS reaches above 30 Gbps".
	We also show that "our adaptive CPU/GPU load balancer reaches near-optimal throughput in various combinations of sample applications and traffic conditions".
	 In this work we propose a software-based packet process-ing framework called NBA (Network Balancing Act). It exploits the latest  hardware advances, but encapsulates their low-level specifics.

	["SIGCOMM 2016"] "ClickNP": Highly Flexible and High Performance Network Processing with Reconfigurable Hardware
	ClickNP proposes to offload software logic onto programmable hardware (e.g. FPGA) to accelerate individual NFs. 
	Our prototype NFs show that they can process traffic at up to 200 million packets per second with ultra-low latency (< 2μs). Compared to existing software counterparts, with FPGA, ClickNP improves throughput by 10x, while reducing latency by 10x. To the best of our knowledge, ClickNP is the first FPGA-accelerated platform for NFs, written completely in high-level language and achieving 40 Gbps line rate at any packet size.
	
	["OSDI 2016"] "NetBricks": Taking the V out of NFV
	NetBricks [47] abandons VMs or containers, and runs NFs on a single CPU core to improve NF performance.
	The move from hardware middleboxes to software network functions, as advocated by NFV, has proven more challenging than expected. Developing new NFs remains a tedious process, requiring that developers repeatedly rediscover and reapply the same set of optimizations, while current techniques for providing isolation between NFs (using	VMs or containers) incur high performance overheads.

	# Discussion - Accelerate IPsec using special purpose hardware 
	Many studies have been done to "accelerate IPsec using special purpose hardware". 
	Ha et al. ["Asia-Pacific Conference on Advanced System Integrated Circuits 2014"] propose an "ASIC design of IPsec hardware accelerator". Its estimated throughput is 200 Mbps. 
	Hodjat et al. ["ITCC 2004"] propose a "specialized cryptographic coprocessor to accelerate AES processing". The throughput of the AES coprocessor is 3.43 Gbps. 
	Dandalis et al. ["TODAES 2004"], Chodowiec et al. ["ISC 2001"], and Kakarountas et al. ["The Journal of Supercomputing 2006"] implement "IPsec solutions with FPGAs". The FPGA implementation of SHA-1 from Kakarountas et al. achieves a throughput up to 4.2 Gbps. 
	Thoguluva et al. ["DATE 2008"] implemen "IPsec on a mobile application processor SoC that contains a programmable security processor". The IPsec implementation offloads cryptographic algorithms to the security processor. Its performance is up to 8 Mbps. 
	Meng et al. ["INTRUST 2010"] propose "a high-performance network processor solution for IPsec using Cavium OCTEON CN58XX". Their implementation achieves 20 Gbps with packets of 1024B. ["PIPSEA"]

	["Asia-Pacific Conference on Advanced System Integrated Circuits 2014"] ASIC design of IPSec hardware accelerator for network security
	["ITCC 2004"] Architectural Design Features of a Programmable High Throughput AES Coprocessor
	["TODAES 2004"] An Adaptive Cryptographic Engine for Internet Protocol Security Architectures
	["ISC 2001"] Experimental Testing of the Gigabit IPSec-Compliant Implementations of Rijndael and Triple DES Using SLAAC-1V FPGA Accelerator Board
	["The Journal of Supercomputing 2006"] High-Speed FPGA Implementation of Secure Hash Algorithm for IPSec and VPN Applications
	["DATE 2008"] Efficient Software Architecture for IPSec Acceleration Using a Programmable Security Processor
	["INTRUST 2010"] Towards High-performance IPsec on Cavium OCTEON Platform

	["CCS 2016"] "PIPSEA": A Practical IPsec Gateway on Embedded APUs ["Cons of CPU/GPU"] 
	Accelerated Processing Unit (APU) is a heterogeneous multicore processor that contains general-purpose CPU cores and a GPU in a single chip. It also supports Heterogeneous System Architecture (HSA) that provides coherent physically-shared memory between the CPU and the GPU. 
	In this paper, we present the "design and implementation of a high-performance IPsec gateway" using "a low-cost commodity embedded APU". 
	The "HSA supported by the APUs eliminates the data copy overhead between the CPU and the GPU" [cons of CPU/GPU], which is "unavoidable in the previous discrete GPU approaches". 
	The gateway is implemented in OpenCL to exploit the GPU and uses zero-copy packet I/O APIs in DPDK. 
	The IPsec gateway handles the real-world network traffic where each packet has a different workload. 
	The proposed packet scheduling algorithm significantly improves GPU utilization for such traffic. 
	It works not only for APUs but also for discrete GPUs. 
	With three CPU cores and one GPU in the APU, the IPsec gateway "achieves a throughput of 10.36 Gbps with an average latency of 2.79 ms" to perform AES-CBC+HMAC-SHA1 for incoming packets of 1024 bytes.

	["IWSSIP 2017"] FPGA implementation of IPsec protocol suite for multigigabit networks
	The paper presents the hardware implementation of IPsec gateway in FPGA.

	["2012 International Conference on Reconfigurable Computing and FPGAs"] IPSECCO: A Lightweight and Reconfigurable IPSec Core
	In this paper we propose a "reconfigurable lightweight Internet Protocol Security (IPSec) hardware core".
	Our architecture supports the main IPSec protocols; namely Authentication Header (AH), Encapsulating Security Payload(ESP), and Internet Key Exchange (IKE). In this work, the cryptographic algorithms and their modes of operation, which are at the heart of the IPSec protocols, are implemented in hardware. Instead of re-implementing common IPSec configurations, which are deemed “too heavy” for pervasive devices, we evaluate efficient implementations of standardized and/or well-known lightweight and hardware-friendly algorithms. In particular, we examine different versions of PRESENT, GRØSTL, PHOTON, and a very compact ECC core. As a consequence, we present IPSECCO, a core with adequate security and only moderate	resource requirements, making it suitable for lightweight devices. We selected the Xilinx Spartan family of Field Programmable	Gate Arrays ("FPGA") as target platform due its low-power	footprint and reduced costs compared to other FPGAs. Our results show that it is possible to realize a high performance IPSec core even on members of the Spartan-3 family.

#2: Packet delivery acceleration: 
	Intel DPDK [30], 
	ClickOS [38] and 
	NetVM [28, 64] optimize packet delivery from the network interface cards (NICs) to VMs, and between VMs. 
#3: NF modularization: 
	OpenBox [7] modularizes NFs (which is also proposed in [2, 46, 60]) and improves overall performance by sharing common building blocks between NFs and chaining the remaining blocks together.



